# -*- coding: utf-8 -*-
"""3 Model Perbandingan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NhfvIkijQe1J15A88DLMAfVd9u0c4FxP

# from google.colab import files
# files.upload()

!pip install -q kaggle

import os
import zipfile
import tensorflow as tf
import numpy as np
import keras
import seaborn as sns
import matplotlib.pyplot as plt
from keras.applications.resnet50 import ResNet50
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dense
from tensorflow.keras.applications import InceptionV3, Xception
from tensorflow.keras.models import Model
from sklearn.metrics import confusion_matrix, classification_report

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d cashutosh/gender-classification-dataset -p ./data

zip_path = "./data/gender-classification-dataset.zip"
extract_path = "./dataset"

with zipfile.ZipFile(zip_path, "r") as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Dataset extracted to {extract_path}")

row, col = 256, 256

base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(row, col, 3))

for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense(64, activation='relu')(x)
x = tf.keras.layers.Dense(32, activation='relu')(x)

output = tf.keras.layers.Dense(1, activation='sigmoid')(x)

model = tf.keras.models.Model(inputs=base_model.input, outputs=output)

train_dir = "/content/dataset/Training"
val_dir   = "/content/dataset/Validation"

train_dataaug = ImageDataGenerator(
    rescale = 1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.8
)

validation_dataaug = ImageDataGenerator(
    rescale = 1./255,
    validation_split=0.8
)

train_generator = train_dataaug.flow_from_directory(
    train_dir,
    batch_size=32,
    class_mode="binary",
    subset="training"
)

validation_generator = validation_dataaug.flow_from_directory(
    val_dir,
    batch_size=32,
    class_mode="binary",
    shuffle=False,
    subset="training"
)

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

class myCallback(tf.keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs={}):
            if(logs.get('accuracy') > 0.95):
                print("\nReached 95 % accuracy!")
                self.model.stop_training = True

callbacks = myCallback()

history = model.fit(train_generator, validation_data=validation_generator, epochs=5, batch_size=32, callbacks=[callbacks])

# loss curve resnet50

plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history["accuracy"], label="Training Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Training Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss")
plt.show()

# confusion matrix resnet50

y_pred = model.predict(validation_generator)
y_pred_classes = (y_pred > 0.5).astype(int)

y_true = validation_generator.classes

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, cmap="Blues", xticklabels=["Male", "Female"], yticklabels=["Male", "Female"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix ResNet50")
plt.show()

print(classification_report(y_true, y_pred_classes))

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(256,256,3))

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(32, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
output = tf.keras.layers.Dense(1, activation='sigmoid')(x)

inceptionv3 = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
    layer.trainable = False

inceptionv3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history_inceptionv3 = inceptionv3.fit(train_generator, validation_data=validation_generator, epochs=5, batch_size=32, callbacks=[callbacks])

# loss curve inception

plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)
plt.plot(history_inceptionv3.history["accuracy"], label="Training Accuracy")
plt.plot(history_inceptionv3.history["val_accuracy"], label="Validation Training Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_inceptionv3.history["loss"], label="Training Loss")
plt.plot(history_inceptionv3.history["val_loss"], label="Validation Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss")
plt.show()

# confusion matrix inceptionv3

y_pred = inceptionv3.predict(validation_generator)
y_pred_classes = (y_pred > 0.5).astype(int)

y_true = validation_generator.classes

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, cmap="Blues", xticklabels=["Male", "Female"], yticklabels=["Male", "Female"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix InceptionV3")
plt.show()

print(classification_report(y_true, y_pred_classes))

base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(32, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
output = tf.keras.layers.Dense(1, activation='sigmoid')(x)

xception = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
    layer.trainable = False

xception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history_xception = xception.fit(train_generator, validation_data=validation_generator, epochs=5, batch_size=32, callbacks=[callbacks])

# loss curve xception

plt.figure(figsize=(10, 6))

plt.subplot(1, 2, 1)
plt.plot(history_xception.history["accuracy"], label="Training Accuracy")
plt.plot(history_xception.history["val_accuracy"], label="Validation Training Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_xception.history["loss"], label="Training Loss")
plt.plot(history_xception.history["val_loss"], label="Validation Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss")
plt.show()

# confusion matrix xception

y_pred = xception.predict(validation_generator)
y_pred_classes = (y_pred > 0.5).astype(int)

y_true = validation_generator.classes

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, cmap="Blues", xticklabels=["Male", "Female"], yticklabels=["Male", "Female"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix Xception")
plt.show()

print(classification_report(y_true, y_pred_classes))

